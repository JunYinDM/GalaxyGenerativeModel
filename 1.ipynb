{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "\n",
    "\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from tqdm import tqdm\n",
    "from log import Logger\n",
    "#from util import r2, mse, rmse, mae, pp_mse, pp_rmse, pp_mae, pp_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BlurPool(nn.Module):\n",
    "    def __init__(self, stride):\n",
    "        super(BlurPool, self).__init__()\n",
    "        self.kernel = nn.Parameter(torch.from_numpy((np.array([[1, 4, 6, 4, 1],\n",
    "                                              [4, 16, 24, 16, 4],\n",
    "                                              [6, 24, 36, 24, 6],\n",
    "                                              [4, 16, 24, 16, 4],\n",
    "                                              [1, 4, 6, 4, 1]])/256.0).astype('float32')),\n",
    "                                   requires_grad=False).view(1, 1, 5, 5)\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        num_dims = x.size(1)\n",
    "        kernel = self.kernel.repeat(num_dims, 1, 1, 1).to(x.device)\n",
    "        x = F.conv2d(x, kernel, groups=num_dims, stride=self.stride, padding=2)\n",
    "        return x\n",
    "    \n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, anti_alias=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        if anti_alias and stride != 1:\n",
    "            self.conv1 = nn.Sequential(conv3x3(inplanes, planes, 1),\n",
    "                                       nn.BatchNorm2d(planes),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       BlurPool(stride=stride))\n",
    "        else:\n",
    "            self.conv1 = nn.Sequential(conv3x3(inplanes, planes, stride),\n",
    "                                       nn.BatchNorm2d(planes),\n",
    "                                       nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model   \n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model\n",
    "\n",
    "class SelfAttn(nn.Module):\n",
    "    \"\"\" Self attention Layer\"\"\"\n",
    "\n",
    "    def __init__(self, in_dim):\n",
    "        super(SelfAttn, self).__init__()\n",
    "        self.chanel_in = in_dim\n",
    "\n",
    "        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim // 2, kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim // 2, kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(in_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            inputs :\n",
    "                x : input feature maps( B X C X W X H)\n",
    "            returns :\n",
    "                out : self attention value + input feature\n",
    "                attention: B X N X N (N is Width*Height)\n",
    "        \"\"\"\n",
    "        batch_size, num_dims, width, height = x.size()\n",
    "        proj_query = self.query_conv(x).view(batch_size, -1, width * height).permute(0, 2, 1)  # B X C X N\n",
    "        proj_key = self.key_conv(x).view(batch_size, -1, width * height)  # B X C x (*W*H)\n",
    "        energy = torch.bmm(proj_query, proj_key)  # transpose check\n",
    "        q_k = math.sqrt(num_dims // 2)\n",
    "        attention = F.softmax(energy/q_k, dim=2)  # BX (N) X (N)\n",
    "        proj_value = x.view(batch_size, num_dims, -1)  # B X C X N\n",
    "\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
    "        out = out.view(batch_size, num_dims, width, height)\n",
    "\n",
    "        out = self.value_conv(out)\n",
    "\n",
    "        out = self.bn(out)\n",
    "\n",
    "        out = out + x\n",
    "        return out\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, in_dims=128):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_dims+2, in_dims, 1, stride=1, bias=False),\n",
    "                                  nn.BatchNorm2d(in_dims),\n",
    "                                  nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_dims, width, height = x.size()\n",
    "        width_axis = torch.arange(-width//2, width//2, step=1, dtype=x.dtype,\n",
    "                                  device=x.device).view(1, 1, width, 1).repeat(1, 1, 1, height)\n",
    "        height_axis = torch.arange(-height//2, height//2, step=1, dtype=x.dtype,\n",
    "                                   device=x.device).view(1, 1, 1, height).repeat(1, 1, width, 1)\n",
    "        axis = torch.cat((width_axis, height_axis), dim=1).repeat(batch_size, 1, 1, 1)\n",
    "        x = torch.cat((x, axis), dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_outputs=128, zero_init_residual=True, non_local=False,\n",
    "                 anti_alias=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.anti_alias = anti_alias\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], anti_alias=anti_alias)\n",
    "        if non_local:\n",
    "            self.layer1 = nn.Sequential(self.layer1,\n",
    "                                        SelfAttn(64))\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, anti_alias=anti_alias)\n",
    "        if non_local:\n",
    "            self.layer2 = nn.Sequential(self.layer2,\n",
    "                                        SelfAttn(128))\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, anti_alias=anti_alias)\n",
    "        if non_local:\n",
    "            self.layer3 = nn.Sequential(self.layer3,\n",
    "                                        SelfAttn(256))\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, anti_alias=anti_alias)\n",
    "        if non_local:\n",
    "            self.layer4 = nn.Sequential(self.layer4,\n",
    "                                        SelfAttn(512))\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_outputs)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "                elif isinstance(m, SelfAttn):\n",
    "                    nn.init.constant_(m.bn.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, anti_alias=False):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Sequential(conv1x1(self.inplanes, planes * block.expansion, 1),\n",
    "                              BlurPool(stride=stride))\n",
    "                if anti_alias else conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, anti_alias=anti_alias))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.num_parameters = args.num_parameters\n",
    "        self.nn = nn.Sequential(nn.Conv2d(1+self.num_parameters, 64, 3, stride=2, bias=False),\n",
    "                                nn.BatchNorm2d(64),\n",
    "                                nn.LeakyReLU(0.2, True),\n",
    "                                nn.Conv2d(64, 128, 3, stride=2, bias=False),\n",
    "                                nn.BatchNorm2d(128),\n",
    "                                nn.LeakyReLU(0.2, True),\n",
    "                                nn.Conv2d(128, 256, 3, stride=2, bias=False),\n",
    "                                nn.BatchNorm2d(256),\n",
    "                                nn.LeakyReLU(0.2, True),\n",
    "                                nn.Conv2d(256, 512, 3, stride=2, bias=False),\n",
    "                                nn.BatchNorm2d(512),\n",
    "                                nn.LeakyReLU(0.2, True),\n",
    "                                nn.Conv2d(512, 1, 3, stride=1, bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.nn(x)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./gal_img'):\n",
    "    os.mkdir('./gal_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gDataset(Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "\n",
    "    def __init__(self):\n",
    "                \n",
    "        h5 = h5py.File('galaxy.h5','r')\n",
    "        image = h5['img'][:]\n",
    "        h5.close()\n",
    "        \n",
    "        image.astype('float32')\n",
    "        self.len = image.shape[0]\n",
    "        self.img = torch.from_numpy(image[:])\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.img[index]\n",
    "    \n",
    "#    def __getitem__(self, index):\n",
    "#        return self.img[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def to_img(x):\n",
    "    x = x.view(x.size(0), 1, 96, 96)\n",
    "    return x\n",
    "\n",
    "num_epochs =1000\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "\n",
    "\n",
    "def plot_sample_img(img, name):\n",
    "    img = img.view(1, 96, 96)\n",
    "    save_image(img, './sample_{}.png'.format(name))\n",
    "\n",
    "\n",
    "def min_max_normalization(tensor, min_value, max_value):\n",
    "    min_tensor = tensor.min()\n",
    "    tensor = (tensor - min_tensor)\n",
    "    max_tensor = tensor.max()\n",
    "    tensor = tensor / max_tensor\n",
    "    tensor = tensor * (max_value - min_value) + min_value\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def tensor_round(tensor):\n",
    "    return torch.round(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= gDataset()\n",
    "dataloader= DataLoader(dataset=dataset, batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(96 * 96, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Linear(64, 10),\n",
    "            nn.ReLU(True))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(10, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 96 * 96),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder().cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/1000], loss:0.0143, MSE_loss:0.0001\n",
      "epoch [2/1000], loss:0.0152, MSE_loss:0.0001\n",
      "epoch [3/1000], loss:0.0103, MSE_loss:0.0001\n",
      "epoch [4/1000], loss:0.0130, MSE_loss:0.0004\n",
      "epoch [5/1000], loss:0.0138, MSE_loss:0.0001\n",
      "epoch [6/1000], loss:0.0145, MSE_loss:0.0002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0689c18be9cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# ===================log========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     print('epoch [{}/{}], loss:{:.4f}, MSE_loss:{:.4f}'\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                     \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img = data\n",
    "        \n",
    "        \n",
    "        #\n",
    "        img.type(torch.float32)\n",
    "\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img).cuda().type('torch.FloatTensor')\n",
    "        \n",
    "\n",
    "        # ===================forward=====================\n",
    "\n",
    "        output = model(img.cuda())\n",
    "\n",
    "        loss = criterion(output.cuda(), img.cuda())\n",
    "        MSE_loss = nn.MSELoss()(output.cuda(), img.cuda())\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}, MSE_loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, loss.data, MSE_loss.data))\n",
    "    if epoch % 10 == 0:\n",
    "        x = to_img(img.cpu().data)\n",
    "        x_hat = to_img(output.cpu().data)\n",
    "        save_image(x, './gal_img/x_{}.png'.format(epoch))\n",
    "        save_image(x_hat, './gal_img/x_hat_{}.png'.format(epoch))\n",
    "\n",
    "torch.save(model.state_dict(), './sim_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
