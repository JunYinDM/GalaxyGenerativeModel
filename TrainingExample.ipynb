{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from log import Logger\n",
    "from data import gDataset, trainDataset, testDataset\n",
    "from util import r2, mse, rmse, mae, pp_mse, pp_rmse, pp_mae\n",
    "from model import autoencoder_0, autoencoder_1, autoencoder_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./gal_img'):\n",
    "    os.mkdir('./gal_img')\n",
    "\n",
    "    \n",
    "    \n",
    "def to_img(x):\n",
    "    x = x.view(x.size(0), 1, 96, 96)\n",
    "    return x\n",
    "\n",
    "num_epochs =1000\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "\n",
    "\n",
    "def plot_sample_img(img, name):\n",
    "    img = img.view(1, 96, 96)\n",
    "    save_image(img, './sample_{}.png'.format(name))\n",
    "\n",
    "\n",
    "def min_max_normalization(tensor, min_value, max_value):\n",
    "    min_tensor = tensor.min()\n",
    "    tensor = (tensor - min_tensor)\n",
    "    max_tensor = tensor.max()\n",
    "    tensor = tensor / max_tensor\n",
    "    tensor = tensor * (max_value - min_value) + min_value\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def tensor_round(tensor):\n",
    "    return torch.round(tensor)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= gDataset()\n",
    "dataloader= DataLoader(dataset=dataset, batch_size=64,shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "model = autoencoder_2().cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/1000], loss:0.6599, MSE_loss:0.2312\n",
      "epoch [2/1000], loss:0.6428, MSE_loss:0.2216\n",
      "epoch [3/1000], loss:0.6098, MSE_loss:0.2056\n",
      "epoch [4/1000], loss:0.5456, MSE_loss:0.1744\n",
      "epoch [5/1000], loss:0.4615, MSE_loss:0.1404\n",
      "epoch [6/1000], loss:0.3914, MSE_loss:0.1151\n",
      "epoch [7/1000], loss:0.3462, MSE_loss:0.1003\n",
      "epoch [8/1000], loss:0.3254, MSE_loss:0.0906\n",
      "epoch [9/1000], loss:0.2985, MSE_loss:0.0852\n",
      "epoch [10/1000], loss:0.2863, MSE_loss:0.0796\n",
      "epoch [11/1000], loss:0.2760, MSE_loss:0.0745\n",
      "epoch [12/1000], loss:0.2625, MSE_loss:0.0699\n",
      "epoch [13/1000], loss:0.2510, MSE_loss:0.0653\n",
      "epoch [14/1000], loss:0.2422, MSE_loss:0.0606\n",
      "epoch [15/1000], loss:0.2366, MSE_loss:0.0573\n",
      "epoch [16/1000], loss:0.2142, MSE_loss:0.0515\n",
      "epoch [17/1000], loss:0.2013, MSE_loss:0.0470\n",
      "epoch [18/1000], loss:0.1889, MSE_loss:0.0423\n",
      "epoch [19/1000], loss:0.1766, MSE_loss:0.0384\n",
      "epoch [20/1000], loss:0.1689, MSE_loss:0.0344\n",
      "epoch [21/1000], loss:0.1583, MSE_loss:0.0309\n",
      "epoch [22/1000], loss:0.1507, MSE_loss:0.0278\n",
      "epoch [23/1000], loss:0.1434, MSE_loss:0.0245\n",
      "epoch [24/1000], loss:0.1319, MSE_loss:0.0220\n",
      "epoch [25/1000], loss:0.1220, MSE_loss:0.0196\n",
      "epoch [26/1000], loss:0.1162, MSE_loss:0.0172\n",
      "epoch [27/1000], loss:0.1094, MSE_loss:0.0151\n",
      "epoch [28/1000], loss:0.1030, MSE_loss:0.0132\n",
      "epoch [29/1000], loss:0.0942, MSE_loss:0.0116\n",
      "epoch [30/1000], loss:0.0944, MSE_loss:0.0103\n",
      "epoch [31/1000], loss:0.0831, MSE_loss:0.0090\n",
      "epoch [32/1000], loss:0.0870, MSE_loss:0.0093\n",
      "epoch [33/1000], loss:0.0735, MSE_loss:0.0067\n",
      "epoch [34/1000], loss:0.0719, MSE_loss:0.0059\n",
      "epoch [35/1000], loss:0.0731, MSE_loss:0.0085\n",
      "epoch [36/1000], loss:0.0597, MSE_loss:0.0045\n",
      "epoch [37/1000], loss:0.0586, MSE_loss:0.0040\n",
      "epoch [38/1000], loss:0.0602, MSE_loss:0.0040\n",
      "epoch [39/1000], loss:0.0519, MSE_loss:0.0030\n",
      "epoch [40/1000], loss:0.0546, MSE_loss:0.0036\n",
      "epoch [41/1000], loss:0.0465, MSE_loss:0.0024\n",
      "epoch [42/1000], loss:0.0460, MSE_loss:0.0021\n",
      "epoch [43/1000], loss:0.0388, MSE_loss:0.0017\n",
      "epoch [44/1000], loss:0.0398, MSE_loss:0.0015\n",
      "epoch [45/1000], loss:0.0364, MSE_loss:0.0014\n",
      "epoch [46/1000], loss:0.0379, MSE_loss:0.0014\n",
      "epoch [47/1000], loss:0.0322, MSE_loss:0.0010\n",
      "epoch [48/1000], loss:0.0323, MSE_loss:0.0010\n",
      "epoch [49/1000], loss:0.0294, MSE_loss:0.0009\n",
      "epoch [50/1000], loss:0.0336, MSE_loss:0.0010\n",
      "epoch [51/1000], loss:0.0306, MSE_loss:0.0008\n",
      "epoch [52/1000], loss:0.0311, MSE_loss:0.0016\n",
      "epoch [53/1000], loss:0.0299, MSE_loss:0.0007\n",
      "epoch [54/1000], loss:0.0284, MSE_loss:0.0006\n",
      "epoch [55/1000], loss:0.0250, MSE_loss:0.0005\n",
      "epoch [56/1000], loss:0.0262, MSE_loss:0.0005\n",
      "epoch [57/1000], loss:0.0240, MSE_loss:0.0004\n",
      "epoch [58/1000], loss:0.0225, MSE_loss:0.0004\n",
      "epoch [59/1000], loss:0.0219, MSE_loss:0.0003\n",
      "epoch [60/1000], loss:0.0173, MSE_loss:0.0003\n",
      "epoch [61/1000], loss:0.0229, MSE_loss:0.0004\n",
      "epoch [62/1000], loss:0.0247, MSE_loss:0.0004\n",
      "epoch [63/1000], loss:0.0231, MSE_loss:0.0003\n",
      "epoch [64/1000], loss:0.0347, MSE_loss:0.0033\n",
      "epoch [65/1000], loss:0.0210, MSE_loss:0.0003\n",
      "epoch [66/1000], loss:0.0209, MSE_loss:0.0003\n",
      "epoch [67/1000], loss:0.0208, MSE_loss:0.0003\n",
      "epoch [68/1000], loss:0.0157, MSE_loss:0.0002\n",
      "epoch [69/1000], loss:0.0188, MSE_loss:0.0003\n",
      "epoch [70/1000], loss:0.0167, MSE_loss:0.0003\n",
      "epoch [71/1000], loss:0.0154, MSE_loss:0.0003\n",
      "epoch [72/1000], loss:0.0167, MSE_loss:0.0003\n",
      "epoch [73/1000], loss:0.0276, MSE_loss:0.0013\n",
      "epoch [74/1000], loss:0.0190, MSE_loss:0.0003\n",
      "epoch [75/1000], loss:0.0258, MSE_loss:0.0004\n",
      "epoch [76/1000], loss:0.0311, MSE_loss:0.0024\n",
      "epoch [77/1000], loss:0.0246, MSE_loss:0.0004\n",
      "epoch [78/1000], loss:0.0213, MSE_loss:0.0003\n",
      "epoch [79/1000], loss:0.0219, MSE_loss:0.0003\n",
      "epoch [80/1000], loss:0.0203, MSE_loss:0.0003\n",
      "epoch [81/1000], loss:0.0196, MSE_loss:0.0003\n",
      "epoch [82/1000], loss:0.0132, MSE_loss:0.0002\n",
      "epoch [83/1000], loss:0.0186, MSE_loss:0.0003\n",
      "epoch [84/1000], loss:0.0260, MSE_loss:0.0006\n",
      "epoch [85/1000], loss:0.0209, MSE_loss:0.0003\n",
      "epoch [86/1000], loss:0.0224, MSE_loss:0.0009\n",
      "epoch [87/1000], loss:0.0230, MSE_loss:0.0004\n",
      "epoch [88/1000], loss:0.0176, MSE_loss:0.0003\n",
      "epoch [89/1000], loss:0.0183, MSE_loss:0.0003\n",
      "epoch [90/1000], loss:0.0216, MSE_loss:0.0003\n",
      "epoch [91/1000], loss:0.0179, MSE_loss:0.0003\n",
      "epoch [92/1000], loss:0.0168, MSE_loss:0.0002\n",
      "epoch [93/1000], loss:0.0224, MSE_loss:0.0003\n",
      "epoch [94/1000], loss:0.0198, MSE_loss:0.0005\n",
      "epoch [95/1000], loss:0.0170, MSE_loss:0.0002\n",
      "epoch [96/1000], loss:0.0199, MSE_loss:0.0003\n",
      "epoch [97/1000], loss:0.0190, MSE_loss:0.0002\n",
      "epoch [98/1000], loss:0.0160, MSE_loss:0.0002\n",
      "epoch [99/1000], loss:0.0165, MSE_loss:0.0002\n",
      "epoch [100/1000], loss:0.0152, MSE_loss:0.0002\n",
      "epoch [101/1000], loss:0.0136, MSE_loss:0.0002\n",
      "epoch [102/1000], loss:0.0153, MSE_loss:0.0002\n",
      "epoch [103/1000], loss:0.0197, MSE_loss:0.0003\n",
      "epoch [104/1000], loss:0.0211, MSE_loss:0.0003\n",
      "epoch [105/1000], loss:0.0219, MSE_loss:0.0003\n",
      "epoch [106/1000], loss:0.0180, MSE_loss:0.0003\n",
      "epoch [107/1000], loss:0.0153, MSE_loss:0.0002\n",
      "epoch [108/1000], loss:0.0227, MSE_loss:0.0003\n",
      "epoch [109/1000], loss:0.0135, MSE_loss:0.0002\n",
      "epoch [110/1000], loss:0.0231, MSE_loss:0.0003\n",
      "epoch [111/1000], loss:0.0228, MSE_loss:0.0010\n",
      "epoch [112/1000], loss:0.0177, MSE_loss:0.0002\n",
      "epoch [113/1000], loss:0.0153, MSE_loss:0.0002\n",
      "epoch [114/1000], loss:0.0131, MSE_loss:0.0002\n",
      "epoch [115/1000], loss:0.0169, MSE_loss:0.0002\n",
      "epoch [116/1000], loss:0.0199, MSE_loss:0.0003\n",
      "epoch [117/1000], loss:0.0160, MSE_loss:0.0002\n",
      "epoch [118/1000], loss:0.0169, MSE_loss:0.0002\n",
      "epoch [119/1000], loss:0.0228, MSE_loss:0.0004\n",
      "epoch [120/1000], loss:0.0207, MSE_loss:0.0004\n",
      "epoch [121/1000], loss:0.0244, MSE_loss:0.0006\n",
      "epoch [122/1000], loss:0.0187, MSE_loss:0.0002\n",
      "epoch [123/1000], loss:0.0140, MSE_loss:0.0002\n",
      "epoch [124/1000], loss:0.0156, MSE_loss:0.0002\n",
      "epoch [125/1000], loss:0.0198, MSE_loss:0.0003\n",
      "epoch [126/1000], loss:0.0177, MSE_loss:0.0002\n",
      "epoch [127/1000], loss:0.0162, MSE_loss:0.0002\n",
      "epoch [128/1000], loss:0.0221, MSE_loss:0.0005\n",
      "epoch [129/1000], loss:0.0176, MSE_loss:0.0002\n",
      "epoch [130/1000], loss:0.0184, MSE_loss:0.0007\n",
      "epoch [131/1000], loss:0.0145, MSE_loss:0.0002\n",
      "epoch [132/1000], loss:0.0160, MSE_loss:0.0002\n",
      "epoch [133/1000], loss:0.0212, MSE_loss:0.0005\n",
      "epoch [134/1000], loss:0.0140, MSE_loss:0.0002\n",
      "epoch [135/1000], loss:0.0173, MSE_loss:0.0003\n",
      "epoch [136/1000], loss:0.0186, MSE_loss:0.0003\n",
      "epoch [137/1000], loss:0.0270, MSE_loss:0.0011\n",
      "epoch [138/1000], loss:0.0161, MSE_loss:0.0002\n",
      "epoch [139/1000], loss:0.0222, MSE_loss:0.0004\n",
      "epoch [140/1000], loss:0.0170, MSE_loss:0.0002\n",
      "epoch [141/1000], loss:0.0176, MSE_loss:0.0003\n",
      "epoch [142/1000], loss:0.0207, MSE_loss:0.0003\n",
      "epoch [143/1000], loss:0.0199, MSE_loss:0.0003\n",
      "epoch [144/1000], loss:0.0165, MSE_loss:0.0028\n",
      "epoch [145/1000], loss:0.0170, MSE_loss:0.0002\n",
      "epoch [146/1000], loss:0.0217, MSE_loss:0.0004\n",
      "epoch [147/1000], loss:0.0233, MSE_loss:0.0004\n",
      "epoch [148/1000], loss:0.0222, MSE_loss:0.0003\n",
      "epoch [149/1000], loss:0.0205, MSE_loss:0.0004\n",
      "epoch [150/1000], loss:0.0179, MSE_loss:0.0003\n",
      "epoch [151/1000], loss:0.0184, MSE_loss:0.0015\n",
      "epoch [152/1000], loss:0.0189, MSE_loss:0.0003\n",
      "epoch [153/1000], loss:0.0194, MSE_loss:0.0003\n",
      "epoch [154/1000], loss:0.0232, MSE_loss:0.0003\n",
      "epoch [155/1000], loss:0.0191, MSE_loss:0.0002\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img = data\n",
    "        \n",
    "        \n",
    "        \n",
    "        img.type(torch.float32)\n",
    "\n",
    "        img = img.view(img.size(0), 1,96,96)\n",
    "        img = Variable(img).cuda().type('torch.FloatTensor')\n",
    "        \n",
    "        #print(img.shape)\n",
    "        \n",
    "\n",
    "        # forward\n",
    "\n",
    "        output = model(img.cuda())\n",
    "        \n",
    "        #print(\"output \",output.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        loss = criterion(output.cuda(), img.cuda())\n",
    "        \n",
    "        MSE_loss = nn.MSELoss()(output.cuda(), img.cuda())\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # log\n",
    "    print('epoch [{}/{}], loss:{:.4f}, MSE_loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, loss.data, MSE_loss.data))\n",
    "    if epoch % 10 == 0:\n",
    "        x = to_img(img.cpu().data)\n",
    "        x_hat = to_img(output.cpu().data)\n",
    "        torch.save(x, './s2_x_{}.pt'.format(epoch))\n",
    "        torch.save(x_hat, './s2_x_hat_{}.pt'.format(epoch))\n",
    "\n",
    "torch.save(model.state_dict(), './s2_sim_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tensor, 'file.pt') and torch.load('s1_x_{}.pt.pt')\n",
    "\n",
    "\n",
    "        save_image(x, './gal_img/9_x_{}.png'.format(epoch))\n",
    "        save_image(x_hat, './gal_img/9_x_hat_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(x.size(0), 1, 96, 96)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 96, 96])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=23):\n",
    "        self.inplanes = 64\n",
    "        super (Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)#, return_indices = True)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, 1000)\n",
    "\t#self.fc = nn.Linear(num_classes,16) \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\t\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\t\n",
    "        x = self.maxpool(x)\n",
    "\t\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "encoder = Encoder(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "encoder.fc = nn.Linear(2048, 48)\n",
    "\n",
    "encoder=encoder.cuda()\n",
    "y=torch.rand(1,3,224,224)\n",
    "x=torch.rand(1,128)\n",
    "x=Variable(x.cuda())\n",
    "\n",
    "zsize=10  \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Decoder,self).__init__()\n",
    "\t\tself.dfc3 = nn.Linear(zsize, 4096)\n",
    "\t\tself.bn3 = nn.BatchNorm2d(4096)\n",
    "\t\tself.dfc2 = nn.Linear(4096, 4096)\n",
    "\t\tself.bn2 = nn.BatchNorm2d(4096)\n",
    "\t\tself.dfc1 = nn.Linear(4096,256 * 6 * 6)\n",
    "\t\tself.bn1 = nn.BatchNorm2d(256*6*6)\n",
    "\t\tself.upsample1=nn.Upsample(scale_factor=2)\n",
    "\t\tself.dconv5 = nn.ConvTranspose2d(256, 256, 3, padding = 0)\n",
    "\t\tself.dconv4 = nn.ConvTranspose2d(256, 384, 3, padding = 1)\n",
    "\t\tself.dconv3 = nn.ConvTranspose2d(384, 192, 3, padding = 1)\n",
    "\t\tself.dconv2 = nn.ConvTranspose2d(192, 64, 5, padding = 2)\n",
    "\t\tself.dconv1 = nn.ConvTranspose2d(64, 3, 12, stride = 4, padding = 4)\n",
    "\n",
    "\tdef forward(self,x):#,i1,i2,i3):\n",
    "\t\t\n",
    "\t\tx = self.dfc3(x)\n",
    "\t\t#x = F.relu(x)\n",
    "\t\tx = F.relu(self.bn3(x))\n",
    "\t\t\n",
    "\t\tx = self.dfc2(x)\n",
    "\t\tx = F.relu(self.bn2(x))\n",
    "\t\t#x = F.relu(x)\n",
    "\t\tx = self.dfc1(x)\n",
    "\t\tx = F.relu(self.bn1(x))\n",
    "\t\t#x = F.relu(x)\n",
    "\t\t#print(x.size())\n",
    "\t\tx = x.view(batch_size,256,6,6)\n",
    "\t\t#print (x.size())\n",
    "\t\tx=self.upsample1(x)\n",
    "\t\t#print x.size()\n",
    "\t\tx = self.dconv5(x)\n",
    "\t\t#print x.size()\n",
    "\t\tx = F.relu(x)\n",
    "\t\t#print x.size()\n",
    "\t\tx = F.relu(self.dconv4(x))\n",
    "\t\t#print x.size()\n",
    "\t\tx = F.relu(self.dconv3(x))\n",
    "\t\t#print x.size()\t\t\n",
    "\t\tx=self.upsample1(x)\n",
    "\t\t#print x.size()\t\t\n",
    "\t\tx = self.dconv2(x)\n",
    "\t\t#print x.size()\t\t\n",
    "\t\tx = F.relu(x)\n",
    "\t\tx=self.upsample1(x)\n",
    "\t\t#print x.size()\n",
    "\t\tx = self.dconv1(x)\n",
    "\t\t#print x.size()\n",
    "\t\tx = F.sigmoid(x)\n",
    "\t\t#print x\n",
    "\t\treturn x\n",
    "decoder = Decoder()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(autoencoder,self).__init__()\n",
    "\t\tself.encoder = encoder(x)\n",
    "\t\tself.decoder = decoder()\n",
    "\n",
    "\tdef forward(self,x):\n",
    "\t\t#x=Encoder(x)\n",
    "\t\tx = self.encoder(x)\n",
    "\n",
    "\t\tx = self.decoder(x)\n",
    "\t\treturn x\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
