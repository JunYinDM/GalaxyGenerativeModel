{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from tqdm import tqdm\n",
    "import tensorboard\n",
    "import tensorboardX\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from log import Logger\n",
    "from data import gDataset, trainDataset, testDataset\n",
    "from util import r2, mse, rmse, mae, pp_mse, pp_rmse, pp_mae\n",
    "from model import autoencoder_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('./gal_img917'):\n",
    "    os.mkdir('./gal_img917')\n",
    "\n",
    "    \n",
    "    \n",
    "def to_img(x):   # image size 56 * 56 \n",
    "    x = x.view(x.size(0), 1, 56, 56)\n",
    "    return x\n",
    "\n",
    "dataset= trainDataset()\n",
    "dataloader= DataLoader(dataset=dataset, batch_size=64,shuffle=True)\n",
    "\n",
    "test_dataset = testDataset()\n",
    "test_dataloader= DataLoader(dataset=test_dataset, batch_size=64,shuffle=True)\n",
    "\n",
    "\n",
    "writer = SummaryWriter(\"run917/exp2_ae6_lr1e4_2000_5000_wd1e5_tt\",)  ##### change name \n",
    "\n",
    "num_epochs =10000\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "\n",
    "model = autoencoder_6().cuda()   ###### AE model \n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "#scheduler \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[2000,5000], gamma=0.1)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    total_mse = 0.0 \n",
    "    num_examples = 0.0\n",
    "    test_num_examples=0.0\n",
    "    \n",
    "    \n",
    "    test_total_loss = 0.0    \n",
    "    test_total_mse=0.0\n",
    "    \n",
    "    model.train()\n",
    "    for data in dataloader:\n",
    "        img = data\n",
    "        img = img.type(torch.float32)\n",
    "        img = img.view(img.size(0), 1,56,56)\n",
    "        img = img.cuda()\n",
    "       # print(img.shape)\n",
    "        \n",
    "\n",
    "        # forward\n",
    "        output = model(img)\n",
    "                \n",
    "       #print(\"output \",output.shape)\n",
    "        loss = criterion(output.cuda(), img)\n",
    "        MSE_loss = nn.MSELoss()(output.cuda(), img)\n",
    "        batch_size = img.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_mse += MSE_loss.item() * batch_size\n",
    "        num_examples += batch_size\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "    # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    model.eval()\n",
    "    for data in test_dataloader:\n",
    "        test_img = data\n",
    "        test_img = test_img.type(torch.float32)\n",
    "        test_img = test_img.view(test_img.size(0), 1,56,56)\n",
    "        test_img = test_img.cuda()\n",
    "       # print(img.shape)\n",
    "        \n",
    "\n",
    "        # forward\n",
    "        test_output = model(test_img)\n",
    "                \n",
    "       #print(\"output \",output.shape)\n",
    "        test_loss = criterion(test_output.cuda(), test_img)\n",
    "        test_MSE_loss = nn.MSELoss()(test_output.cuda(), test_img)\n",
    "        batch_size = test_img.size(0)\n",
    "        test_total_loss += test_loss.item() * batch_size\n",
    "        test_total_mse += test_MSE_loss.item() * batch_size\n",
    "        test_num_examples += batch_size\n",
    "\n",
    "        \n",
    "    writer.add_scalar('Loss/train',total_loss / num_examples,epoch)\n",
    "    writer.add_scalar('Mse/train', total_mse / num_examples,epoch)        \n",
    "    writer.add_scalar('Loss/test',test_total_loss / test_num_examples,epoch)\n",
    "    writer.add_scalar('Mse/test', test_total_mse / test_num_examples,epoch)\n",
    "    \n",
    "\n",
    "        \n",
    "    ''' \n",
    "    print('epoch [{}/{}], loss:{:.4f}, MSE_loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, total_loss / num_examples, total_mse/ num_examples))    \n",
    "    print(' epoch [{}/{}],test_loss:{:.4f}, test_MSE_loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, test_total_loss / test_num_examples, test_total_mse/ test_num_examples))\n",
    "    '''\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        x = to_img(img.cpu().data)\n",
    "        x_hat = to_img(output.cpu().data)\n",
    "        test_x = to_img(test_img.cpu().data)    ########## change name \n",
    "        test_x_hat = to_img(test_output.cpu().data)\n",
    "        torch.save(x, './gal_img917/exp2_x_{}.pt'.format(epoch))\n",
    "        torch.save(x_hat, './gal_img917/exp2_x_hat_{}.pt'.format(epoch))\n",
    "        torch.save(test_x, './gal_img917/exp2_test_x_{}.pt'.format(epoch))\n",
    "        torch.save(test_x_hat, './gal_img917/exp2_test_x_hat_{}.pt'.format(epoch))\n",
    "        \n",
    "        \n",
    "torch.save(model.state_dict(), './gal_img917/exp2_sim_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones(1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = loss.cpu().detach().numpy()\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = visdom.Visdom()\n",
    "\n",
    "\n",
    "loss_window = vis.line(\n",
    "    X=torch.zeros((1,)).cpu(),\n",
    "    Y=torch.zeros((1)).cpu(),\n",
    "    opts=dict(xlabel='epoch',ylabel='Loss',title='training loss',legend=['Loss']))\n",
    "\n",
    "vis.line(X=torch.ones((1,1)).cpu()*epoch,Y=torch.Tensor([loss.data]).unsqueeze(0).cpu(),win=loss_window,update='append')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder_5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder_5, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=3, padding=1),  \n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2), \n",
    "            \n",
    "            nn.Conv2d(16, 8, 3, stride=2, padding=1),  \n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1),  \n",
    "            \n",
    "            nn.Conv2d(8, 2, 3, stride=1, padding=1),  # b, 2,\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1),  # b, 2,\n",
    "            \n",
    "            nn.Conv2d(2, 1, 3, stride=2, padding=1),  # b, 1, 3, 3 \n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            # output = (input - 1 ) * stride -2 * padding + kernel size\n",
    "            \n",
    "            nn.ConvTranspose2d(1, 2, 3, stride=1),  # b, 2,  4 , 4 \n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(2, 8, 3, stride=3, padding =1  ),  # b, 8, 10 , 10 \n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding =1  ),  # b, 8, 19 , 19 \n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(8, 4, 3, stride=3, padding =1  ),  # b, 8,  55, 55  \n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(4, 1, 3, stride=3, padding =1  ),  # b, 8,  55, 55  \n",
    "            nn.Sigmoid()\n",
    "\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=23):\n",
    "        self.inplanes = 64\n",
    "        super (Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)#, return_indices = True)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, 1000)\n",
    "\t#self.fc = nn.Linear(num_classes,16) \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\t\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\t\n",
    "        x = self.maxpool(x)\n",
    "\t\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "encoder = Encoder(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "encoder.fc = nn.Linear(2048, 48)\n",
    "\n",
    "encoder=encoder.cuda()\n",
    "y=torch.rand(1,3,224,224)\n",
    "x=torch.rand(1,128)\n",
    "x=Variable(x.cuda())\n",
    "\n",
    "zsize=10  \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Decoder,self).__init__()\n",
    "\t\tself.dfc3 = nn.Linear(zsize, 4096)\n",
    "\t\tself.bn3 = nn.BatchNorm2d(4096)\n",
    "\t\tself.dfc2 = nn.Linear(4096, 4096)\n",
    "\t\tself.bn2 = nn.BatchNorm2d(4096)\n",
    "\t\tself.dfc1 = nn.Linear(4096,256 * 6 * 6)\n",
    "\t\tself.bn1 = nn.BatchNorm2d(256*6*6)\n",
    "\t\tself.upsample1=nn.Upsample(scale_factor=2)\n",
    "\t\tself.dconv5 = nn.ConvTranspose2d(256, 256, 3, padding = 0)\n",
    "\t\tself.dconv4 = nn.ConvTranspose2d(256, 384, 3, padding = 1)\n",
    "\t\tself.dconv3 = nn.ConvTranspose2d(384, 192, 3, padding = 1)\n",
    "\t\tself.dconv2 = nn.ConvTranspose2d(192, 64, 5, padding = 2)\n",
    "\t\tself.dconv1 = nn.ConvTranspose2d(64, 3, 12, stride = 4, padding = 4)\n",
    "\n",
    "\tdef forward(self,x):#,i1,i2,i3):\n",
    "\t\t\n",
    "\t\tx = self.dfc3(x)\n",
    "\t\t#x = F.relu(x)\n",
    "\t\tx = F.relu(self.bn3(x))\n",
    "\t\t\n",
    "\t\tx = self.dfc2(x)\n",
    "\t\tx = F.relu(self.bn2(x))\n",
    "\t\t#x = F.relu(x)\n",
    "\t\tx = self.dfc1(x)\n",
    "\t\tx = F.relu(self.bn1(x))\n",
    "\t\t#x = F.relu(x)\n",
    "\t\t#print(x.size())\n",
    "\t\tx = x.view(batch_size,256,6,6)\n",
    "\t\t#print (x.size())\n",
    "\t\tx=self.upsample1(x)\n",
    "\t\t#print x.size()\n",
    "\t\tx = self.dconv5(x)\n",
    "\t\t#print x.size()\n",
    "\t\tx = F.relu(x)\n",
    "\t\t#print x.size()\n",
    "\t\tx = F.relu(self.dconv4(x))\n",
    "\t\t#print x.size()\n",
    "\t\tx = F.relu(self.dconv3(x))\n",
    "\t\t#print x.size()\t\t\n",
    "\t\tx=self.upsample1(x)\n",
    "\t\t#print x.size()\t\t\n",
    "\t\tx = self.dconv2(x)\n",
    "\t\t#print x.size()\t\t\n",
    "\t\tx = F.relu(x)\n",
    "\t\tx=self.upsample1(x)\n",
    "\t\t#print x.size()\n",
    "\t\tx = self.dconv1(x)\n",
    "\t\t#print x.size()\n",
    "\t\tx = F.sigmoid(x)\n",
    "\t\t#print x\n",
    "\t\treturn x\n",
    "decoder = Decoder()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(autoencoder,self).__init__()\n",
    "\t\tself.encoder = encoder(x)\n",
    "\t\tself.decoder = decoder()\n",
    "\n",
    "\tdef forward(self,x):\n",
    "\t\t#x=Encoder(x)\n",
    "\t\tx = self.encoder(x)\n",
    "\n",
    "\t\tx = self.decoder(x)\n",
    "\t\treturn x\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_sample_img(img, name):\n",
    "    img = img.view(1, 56, 56)\n",
    "    save_image(img, './sample_{}.png'.format(name))\n",
    "\n",
    "\n",
    "def min_max_normalization(tensor, min_value, max_value):\n",
    "    min_tensor = tensor.min()\n",
    "    tensor = (tensor - min_tensor)\n",
    "    max_tensor = tensor.max()\n",
    "    tensor = tensor / max_tensor\n",
    "    tensor = tensor * (max_value - min_value) + min_value\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def tensor_round(tensor):\n",
    "    return torch.round(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
