{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorboard\n",
    "import tensorboardX\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from log import Logger\n",
    "from data import  trainDataset, testDataset, trainlabelDataset,testlabelDataset\n",
    "from util import r2, mse, rmse, mae, pp_mse, pp_rmse, pp_mae\n",
    "from model import autoencoder_999, autoencoder_333\n",
    "\n",
    "def to_img(x):   # image size \n",
    "    x = x.view(x.size(0), 1, 64, 64)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists('./gal_img1001'):\n",
    "    os.mkdir('./gal_img1001')\n",
    "\n",
    "    \n",
    "dataset= trainlabelDataset()\n",
    "dataloader= DataLoader(dataset=dataset, batch_size=64,shuffle=True,drop_last=True)\n",
    "\n",
    "test_dataset = testlabelDataset()\n",
    "test_dataloader= DataLoader(dataset=test_dataset, batch_size=64,shuffle=True,drop_last=True)\n",
    "\n",
    "\n",
    "writer = SummaryWriter(\"run1001/exp411\",)  ################################################### change name \n",
    "\n",
    "num_epochs =20000\n",
    "batch_size = 64\n",
    "learning_rate = 5e-1\n",
    "\n",
    "model = autoencoder_333().cuda()   ############################################################## AE model \n",
    "model.load_state_dict(torch.load('gal_img1001/exp401_7700.pth'))    ###\n",
    "\n",
    "criterion_mean = nn.L1Loss(reduction='mean')\n",
    "criterion_none = nn.L1Loss(reduction='none')\n",
    "\n",
    "\n",
    "\n",
    "#scheduler \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1000,4000], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/20000], loss:0.036814, MSE_loss:0.000488, recon_loss:0.007313, latent_loss:7177893.464744\n",
      "epoch [1/20000], test_loss:0.011384, test_MSE_loss:0.000150, test_recon_loss:0.002277, test_latent_loss:2144508.451923\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-d5b50642b612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m################################################## Loss function with regularizing Z ########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mcriterion_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mcriterion_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss_recon\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcriterion_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36ml1_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2163\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2164\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2165\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2166\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    total_mse = 0.0 \n",
    "    total_recon=0.0\n",
    "    total_latent=0.0\n",
    "    \n",
    "    num_examples = 0.0\n",
    "    test_num_examples=0.0\n",
    "    \n",
    "    \n",
    "    test_total_loss = 0.0    \n",
    "    test_total_mse=0.0\n",
    "    test_total_recon=0.0\n",
    "    test_total_latent=0.0\n",
    "    model.train()\n",
    "    for data in dataloader:\n",
    "        img,label= [x.type(torch.float32).cuda() for x in data]\n",
    "        img = img.view(img.size(0), 1,64,64)\n",
    "\n",
    "       # print(img.shape)\n",
    "       # print(\"\",img.sum())\n",
    "       # print(\"\",img[0].sum())\n",
    "        # forward\n",
    "        output, z = model(img)\n",
    "        z=z.view(z.size(0),14*14)\n",
    "       # print(\"output \",output.shape)\n",
    "       # print(\"z \",z.shape)\n",
    "    ################################################## Loss function with regularizing Z ########################\n",
    "        \n",
    "        loss= (( criterion_none(output, img)/(img.sum(dim=3).sum(dim=2).sum(dim=1))).mean())* batch_size  + criterion_mean(z[:,:7], label) /(1e10) \n",
    "\n",
    "        loss_recon= criterion_mean(output, img)\n",
    "        loss_latent= criterion_mean(z[:,:7], label)\n",
    "        \n",
    "        \n",
    "        MSE_loss = nn.MSELoss()(output, img)\n",
    "        batch_size = img.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_mse += MSE_loss.item() * batch_size\n",
    "        total_recon+= loss_recon.item() * batch_size\n",
    "        total_latent+= loss_latent.item() * batch_size\n",
    "\n",
    "        num_examples += batch_size\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "    # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    model.eval()\n",
    "    for data in test_dataloader:\n",
    "        test_img,test_label= [x.type(torch.float32).cuda() for x in data]\n",
    "\n",
    "        test_img = test_img.view(test_img.size(0), 1,64,64)\n",
    "       # print(img.shape)\n",
    "        \n",
    "\n",
    "        # forward\n",
    "        test_output,test_z = model(test_img)\n",
    "        test_z=test_z.view(test_z.size(0),14*14)\n",
    "                \n",
    "       #print(\"output \",output.shape)\n",
    "       # test_loss = criterion(test_output, test_img) + criterion(z[:,:7], label) /(1e)  #  + 1e-5*  criterion(test_z[:,:7], test_label) \n",
    "        test_loss= (( criterion_none(test_output, test_img)/(test_img.sum(dim=3).sum(dim=2).sum(dim=1))).mean())* batch_size  + criterion_mean(test_z[:,:7], test_label) /(1e10) \n",
    "        \n",
    "        test_loss_recon= criterion_mean(test_output, test_img)\n",
    "        test_loss_latent= criterion_mean(test_z[:,:7], test_label)\n",
    "        \n",
    "        test_MSE_loss = nn.MSELoss()(test_output, test_img)\n",
    "        batch_size = test_img.size(0)\n",
    "        test_total_loss += test_loss.item() * batch_size\n",
    "        test_total_mse += test_MSE_loss.item() * batch_size\n",
    "        test_total_recon+= test_loss_recon.item() * batch_size\n",
    "        test_total_latent+= test_loss_latent.item() * batch_size\n",
    "\n",
    "\n",
    "        test_num_examples += batch_size\n",
    "\n",
    "    writer.add_scalar('Loss/train',total_loss / num_examples,epoch)\n",
    "    writer.add_scalar('Mse/train', total_mse / num_examples,epoch)   \n",
    "    writer.add_scalar('Recon/train', total_recon / num_examples,epoch)        \n",
    "    writer.add_scalar('Latent/train', total_latent / num_examples,epoch)        \n",
    "    writer.add_scalar('Loss/test',test_total_loss / test_num_examples,epoch)\n",
    "    writer.add_scalar('Mse/test', test_total_mse / test_num_examples,epoch)\n",
    "    writer.add_scalar('Recon/test', test_total_recon / num_examples,epoch)        \n",
    "    writer.add_scalar('Latent/test', test_total_latent / num_examples,epoch)   \n",
    "    \n",
    "    \n",
    "    print('epoch [{}/{}], loss:{:.6f}, MSE_loss:{:.6f}, recon_loss:{:.6f}, latent_loss:{:.6f}'\n",
    "          .format(epoch + 1, num_epochs, total_loss / num_examples, total_mse/ num_examples, total_recon / num_examples, total_latent/ num_examples))     \n",
    "    \n",
    "    print('epoch [{}/{}], test_loss:{:.6f}, test_MSE_loss:{:.6f}, test_recon_loss:{:.6f}, test_latent_loss:{:.6f}'\n",
    "          .format(epoch + 1, num_epochs, test_total_loss / num_examples, test_total_mse/ num_examples, test_total_recon / num_examples, test_total_latent/ num_examples))   \n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        x = to_img(img.cpu().data)\n",
    "        x_hat = to_img(output.cpu().data)\n",
    "        test_x = to_img(test_img.cpu().data)    ########## change name \n",
    "        test_x_hat = to_img(test_output.cpu().data)\n",
    "        torch.save(x, './gal_img1001/exp411_x_{}.pt'.format(epoch))\n",
    "        torch.save(x_hat, './gal_img1001/exp411_x_hat_{}.pt'.format(epoch))\n",
    "        torch.save(test_x, './gal_img1001/exp411_test_x_{}.pt'.format(epoch))\n",
    "        torch.save(test_x_hat, './gal_img1001/exp411_test_x_hat_{}.pt'.format(epoch))\n",
    "        torch.save(model.state_dict(), './gal_img1001/exp411_{}.pth'.format(epoch))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6775, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(z[:,:7], label)/1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 64, 64])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.0610, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0128, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1878.3997, device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1878.3997, device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(output, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0025026624068157617"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.7/1878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0931, device='cuda:0', grad_fn=<L1LossBackward>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.L1Loss()\n",
    "a=criterion(output, img); \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'padding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-f2c93391acdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'padding'"
     ]
    }
   ],
   "source": [
    "b=output.padding(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.L1Loss(reduction='none')\n",
    "a=criterion(output, img)/(img.sum(dim=3).sum(dim=2).sum(dim=1)); \n",
    "a.shape\n",
    "a.mean()   # should i use a.mean * batch size as loss here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 64, 64])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 64, 64])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o=criterion(output, img);\n",
    "o.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=(img.sum(dim=3).sum(dim=2).sum(dim=1));\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 64, 64])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(o/s).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(o/s)[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(o[0]/s[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([376.2002, 375.2029, 388.9969, 375.9528, 390.7440, 384.9583, 374.2820,\n",
       "        392.0765, 372.9592, 369.8050, 371.1211, 370.0914, 372.2965, 371.2819,\n",
       "        373.7209, 378.2418, 387.1617, 385.0990, 374.8397, 393.6779, 379.8616,\n",
       "        383.6038, 388.1667, 367.0530, 375.0070, 371.9666, 387.4290, 359.9841,\n",
       "        393.1495, 375.6053, 397.4240, 371.6236, 392.8053, 380.7062, 385.8667,\n",
       "        375.7635, 371.6948, 391.2544, 369.6983, 375.2678, 392.8057, 376.5280,\n",
       "        357.5658, 381.0408, 372.9804, 393.4394, 400.0808, 392.5591, 389.8239,\n",
       "        366.2178, 384.4406, 402.1572, 396.6655, 375.2169, 382.4720, 387.4206,\n",
       "        373.9464, 378.7662, 389.1381, 382.7741, 369.0723, 389.4471, 396.3343,\n",
       "        390.2250], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(o.view(64,64*64)).sum(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28.8642, device='cuda:0')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 64, 64])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0004, device='cuda:0', grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(o[0]/s[0]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(o[0]/s[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.L1Loss(reduction='none')\n",
    "a=criterion(output, img)/(img.sum(dim=3).sum(dim=2).sum(dim=1)); \n",
    "a[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0984, 0.0982, 0.0982,  ..., 0.0982, 0.0986, 0.0987],\n",
       "          [0.0980, 0.0978, 0.0981,  ..., 0.0986, 0.0988, 0.0983],\n",
       "          [0.0981, 0.0978, 0.0978,  ..., 0.0987, 0.0983, 0.0983],\n",
       "          ...,\n",
       "          [0.0988, 0.0984, 0.0981,  ..., 0.0978, 0.0983, 0.0981],\n",
       "          [0.0987, 0.0980, 0.0986,  ..., 0.0981, 0.0978, 0.0983],\n",
       "          [0.0984, 0.0988, 0.0981,  ..., 0.0984, 0.0982, 0.0983]]],\n",
       "\n",
       "\n",
       "        [[[0.0984, 0.0984, 0.0986,  ..., 0.0980, 0.0983, 0.0981],\n",
       "          [0.0988, 0.0985, 0.0986,  ..., 0.0982, 0.0980, 0.0984],\n",
       "          [0.0986, 0.0986, 0.0985,  ..., 0.0980, 0.0977, 0.0981],\n",
       "          ...,\n",
       "          [0.0979, 0.0982, 0.0984,  ..., 0.0986, 0.0988, 0.0985],\n",
       "          [0.0980, 0.0981, 0.0980,  ..., 0.0986, 0.0987, 0.0985],\n",
       "          [0.0981, 0.0982, 0.0983,  ..., 0.0984, 0.0986, 0.0988]]],\n",
       "\n",
       "\n",
       "        [[[0.0986, 0.0988, 0.0988,  ..., 0.0984, 0.0982, 0.0988],\n",
       "          [0.0987, 0.0988, 0.0985,  ..., 0.0986, 0.0986, 0.0988],\n",
       "          [0.0988, 0.0986, 0.0987,  ..., 0.0984, 0.0985, 0.0986],\n",
       "          ...,\n",
       "          [0.0984, 0.0987, 0.0982,  ..., 0.0986, 0.0988, 0.0987],\n",
       "          [0.0985, 0.0985, 0.0983,  ..., 0.0988, 0.0988, 0.0987],\n",
       "          [0.0986, 0.0983, 0.0986,  ..., 0.0986, 0.0986, 0.0988]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.0986, 0.0985, 0.0986,  ..., 0.0985, 0.0988, 0.0987],\n",
       "          [0.0988, 0.0987, 0.0987,  ..., 0.0987, 0.0982, 0.0989],\n",
       "          [0.0983, 0.0985, 0.0984,  ..., 0.0987, 0.0987, 0.0988],\n",
       "          ...,\n",
       "          [0.0986, 0.0989, 0.0985,  ..., 0.0985, 0.0985, 0.0983],\n",
       "          [0.0987, 0.0989, 0.0989,  ..., 0.0987, 0.0989, 0.0983],\n",
       "          [0.0986, 0.0988, 0.0988,  ..., 0.0986, 0.0985, 0.0986]]],\n",
       "\n",
       "\n",
       "        [[[0.0986, 0.0989, 0.0988,  ..., 0.0986, 0.0987, 0.0985],\n",
       "          [0.0987, 0.0988, 0.0984,  ..., 0.0982, 0.0986, 0.0985],\n",
       "          [0.0985, 0.0988, 0.0989,  ..., 0.0986, 0.0986, 0.0988],\n",
       "          ...,\n",
       "          [0.0989, 0.0984, 0.0986,  ..., 0.0988, 0.0987, 0.0987],\n",
       "          [0.0984, 0.0986, 0.0983,  ..., 0.0986, 0.0986, 0.0985],\n",
       "          [0.0986, 0.0988, 0.0984,  ..., 0.0989, 0.0986, 0.0988]]],\n",
       "\n",
       "\n",
       "        [[[0.0988, 0.0988, 0.0988,  ..., 0.0987, 0.0986, 0.0988],\n",
       "          [0.0987, 0.0987, 0.0988,  ..., 0.0987, 0.0988, 0.0988],\n",
       "          [0.0988, 0.0986, 0.0985,  ..., 0.0988, 0.0988, 0.0987],\n",
       "          ...,\n",
       "          [0.0986, 0.0988, 0.0986,  ..., 0.0988, 0.0988, 0.0989],\n",
       "          [0.0989, 0.0987, 0.0988,  ..., 0.0988, 0.0987, 0.0989],\n",
       "          [0.0985, 0.0987, 0.0986,  ..., 0.0988, 0.0988, 0.0989]]]],\n",
       "       device='cuda:0', grad_fn=<L1LossBackward>)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18.7978, 18.7570, 19.4015, 18.7812, 19.4405, 19.2229, 18.6972, 19.5513,\n",
       "        18.6488, 18.4426, 18.6093, 18.4840, 18.6372, 18.5100, 18.6942, 18.9117,\n",
       "        19.2900, 19.2327, 18.7771, 19.6164, 19.0020, 19.1472, 19.3563, 18.3912,\n",
       "        18.7592, 18.5940, 19.3236, 18.1046, 19.5853, 18.7956, 19.7727, 18.5932,\n",
       "        19.5860, 19.0441, 19.2512, 18.8355, 18.5655, 19.5026, 18.5566, 18.7135,\n",
       "        19.5586, 18.7788, 17.9620, 19.0520, 18.6616, 19.5754, 19.9027, 19.5752,\n",
       "        19.4300, 18.3311, 19.2050, 19.9936, 19.7502, 18.6805, 19.1010, 19.3415,\n",
       "        18.7298, 18.9430, 19.4094, 19.1276, 18.4948, 19.4263, 19.7307, 19.4690],\n",
       "       device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(dim=3).sum(dim=2).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3011], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.L1Loss(reduction='mean')\n",
    "\n",
    "b=torch.zeros(1)\n",
    "for i in range(64): \n",
    "    a=criterion(output[i]/img[i].sum(), img[i]/img[i].sum())\n",
    "    b=b+a \n",
    "    \n",
    "b    # b is not equal to a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0931, device='cuda:0', grad_fn=<L1LossBackward>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.L1Loss(reduction='mean')\n",
    "criterion(output, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0047], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b/64   # b/64 =a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0032, device='cuda:0', grad_fn=<L1LossBackward>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(output[0]/img[0].sum(), img[0]/img[0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.4840, device='cuda:0')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ=(img.sum(dim=3).sum(dim=2).sum(dim=1));\n",
    "summ.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 64, 64])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.sum().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28.8642, 30.7707, 19.7056, 31.3594, 14.3204, 43.1939, 31.3292, 12.9879,\n",
       "        32.5056, 35.2594, 34.2050, 37.6815, 43.6092, 33.7825, 31.6073, 28.0710,\n",
       "        17.9027, 19.9654, 33.7577, 11.3865, 34.9876, 57.9737, 16.8976, 40.3368,\n",
       "        42.4428, 34.4351, 18.1501, 56.5141, 11.9148, 41.8951,  7.6404, 57.7503,\n",
       "        48.9010, 45.3486, 19.8228, 34.8662, 54.7007, 13.8100, 44.1727, 29.8012,\n",
       "        12.2587, 28.6363, 48.9836, 33.4935, 62.1392, 11.6250,  4.9836, 12.5665,\n",
       "        15.2405, 41.1812, 43.9570,  2.9072,  8.3989, 29.8474, 24.8248, 52.9335,\n",
       "        52.2733, 26.3565, 15.9263, 40.8487, 37.3176, 33.3465,  8.7301, 17.5703],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.sum(dim=3).sum(dim=2).sum(dim=1)  # img 64*1*64*64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.7707, device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0931, device='cuda:0', grad_fn=<L1LossBackward>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.L1Loss()\n",
    "criterion(output, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 64, 64])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(47.3108, device='cuda:0')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2064.2173, device='cuda:0')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4420e-06, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " criterion(output, img)/2064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3011], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.7044], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b/64 * 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0002], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3468], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected device cpu and dtype Float but got device cuda:0 and dtype Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-6079fb7dec93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: expected device cpu and dtype Float but got device cuda:0 and dtype Float"
     ]
    }
   ],
   "source": [
    "b=torch.zeros(1)\n",
    "for i in range(64): \n",
    "    a=criterion(output[i], img[i])\n",
    "    b=b+a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1611], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b/img.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.0610, device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2064.2173, device='cuda:0')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4416e-06, device='cuda:0', grad_fn=<L1LossBackward>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(output/img.sum(), img/img.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-47-f29687896808>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-47-f29687896808>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    criterion(z[:,:7]\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "criterion(z[:,:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.8707, device='cuda:0', grad_fn=<L1LossBackward>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " criterion(output, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [5/20000], loss:0.063595, MSE_loss:0.006816, recon_loss:0.063595, latent_loss:0.006816\n"
     ]
    }
   ],
   "source": [
    "print('epoch [{}/{}], loss:{:.6f}, MSE_loss:{:.6f}, recon_loss:{:.6f}, latent_loss:{:.6f}'\n",
    "          .format(epoch + 1, num_epochs, total_loss / num_examples, total_mse/ num_examples, total_recon / num_examples, total_latent/ num_examples))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (16) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-ce0643d7ce20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mcriterion_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#  .mean())  #* batch_size # + criterion_mean(z[:,:7], label) /(1e9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (16) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "        loss= ( criterion_none(output, img)/(img.sum(dim=3).sum(dim=2).sum(dim=1))) #  .mean())  #* batch_size # + criterion_mean(z[:,:7], label) /(1e9) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 64, 64])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_none(output, img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
