{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorboard\n",
    "import tensorboardX\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from log import Logger\n",
    "from data import  trainDataset, testDataset, trainlabelDataset,testlabelDataset\n",
    "from util import r2, mse, rmse, mae, pp_mse, pp_rmse, pp_mae\n",
    "from model import autoencoder_999, autoencoder_333\n",
    "\n",
    "def to_img(x):   # image size \n",
    "    x = x.view(x.size(0), 1, 64, 64)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists('./gal_img1001'):\n",
    "    os.mkdir('./gal_img1001')\n",
    "\n",
    "    \n",
    "dataset= trainlabelDataset()\n",
    "dataloader= DataLoader(dataset=dataset, batch_size=64,shuffle=True,drop_last=True)\n",
    "\n",
    "test_dataset = testlabelDataset()\n",
    "test_dataloader= DataLoader(dataset=test_dataset, batch_size=64,shuffle=True,drop_last=True)\n",
    "\n",
    "\n",
    "writer = SummaryWriter(\"run1001/exp411\",)  ################################################### change name \n",
    "\n",
    "num_epochs =20000\n",
    "batch_size = 64\n",
    "learning_rate = 5e-1\n",
    "\n",
    "model = autoencoder_333().cuda()   ############################################################## AE model \n",
    "model.load_state_dict(torch.load('gal_img1001/exp401_7700.pth'))    ###\n",
    "\n",
    "criterion_mean = nn.L1Loss(reduction='mean')\n",
    "criterion_none = nn.L1Loss(reduction='none')\n",
    "\n",
    "\n",
    "\n",
    "#scheduler \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1000,4000], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/20000], loss:0.004475, MSE_loss:0.000001, recon_loss:0.000703, latent_loss:7178910.346154\n",
      "epoch [1/20000], test_loss:0.000362, test_MSE_loss:0.000000, test_recon_loss:0.000029, test_latent_loss:2151435.467949\n",
      "epoch [2/20000], loss:0.001203, MSE_loss:0.000000, recon_loss:0.000096, latent_loss:7177010.458333\n",
      "epoch [2/20000], test_loss:0.000362, test_MSE_loss:0.000000, test_recon_loss:0.000029, test_latent_loss:2145513.131410\n",
      "epoch [3/20000], loss:0.001209, MSE_loss:0.000000, recon_loss:0.000096, latent_loss:7179687.054487\n",
      "epoch [3/20000], test_loss:0.000348, test_MSE_loss:0.000000, test_recon_loss:0.000029, test_latent_loss:2148801.993590\n",
      "epoch [4/20000], loss:0.001213, MSE_loss:0.000000, recon_loss:0.000097, latent_loss:7179489.903846\n",
      "epoch [4/20000], test_loss:24.451470, test_MSE_loss:5393.292468, test_recon_loss:4.861256, test_latent_loss:2150058.650641\n",
      "epoch [5/20000], loss:0.001188, MSE_loss:0.000000, recon_loss:0.000096, latent_loss:7180879.682692\n",
      "epoch [5/20000], test_loss:59.688594, test_MSE_loss:21365.617413, test_recon_loss:11.136075, test_latent_loss:2149041.060897\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a46e03f79f05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-a46e03f79f05>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    total_mse = 0.0 \n",
    "    total_recon=0.0\n",
    "    total_latent=0.0\n",
    "    \n",
    "    num_examples = 0.0\n",
    "    test_num_examples=0.0\n",
    "    \n",
    "    \n",
    "    test_total_loss = 0.0    \n",
    "    test_total_mse=0.0\n",
    "    test_total_recon=0.0\n",
    "    test_total_latent=0.0\n",
    "    model.train()\n",
    "    for data in dataloader:\n",
    "        img,label= [x.type(torch.float32).cuda() for x in data]\n",
    "        img = img.view(img.size(0), 1,64,64)\n",
    "\n",
    "       # print(img.shape)\n",
    "       # print(\"\",img.sum())\n",
    "       # print(\"\",img[0].sum())\n",
    "        # forward\n",
    "        output, z = model(img)\n",
    "        z=z.view(z.size(0),14*14)\n",
    "       # print(\"output \",output.shape)\n",
    "       # print(\"z \",z.shape)\n",
    "    ################################################## Loss function with regularizing Z ########################\n",
    "        \n",
    "        loss= (( criterion_none(output, img)/(img.sum(dim=3).sum(dim=2).sum(dim=1))).mean()) + (criterion_none(z[:,:7], label)).mean() /(1e10) \n",
    "\n",
    "        loss_recon=(( criterion_none(output, img)/(img.sum(dim=3).sum(dim=2).sum(dim=1))).mean())\n",
    "        loss_latent=(criterion_none(z[:,:7], label)).mean() /(1e10)\n",
    "        \n",
    "        \n",
    "        MSE_loss = nn.MSELoss()(output, img)\n",
    "        batch_size = img.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_mse += MSE_loss.item() * batch_size\n",
    "        total_recon+= loss_recon.item() * batch_size\n",
    "        total_latent+= loss_latent.item() * batch_size\n",
    "\n",
    "        num_examples += batch_size\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "    # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    model.eval()\n",
    "    for data in test_dataloader:\n",
    "        test_img,test_label= [x.type(torch.float32).cuda() for x in data]\n",
    "\n",
    "        test_img = test_img.view(test_img.size(0), 1,64,64)\n",
    "       # print(img.shape)\n",
    "        \n",
    "\n",
    "        # forward\n",
    "        test_output,test_z = model(test_img)\n",
    "        test_z=test_z.view(test_z.size(0),14*14)\n",
    "                \n",
    "       #print(\"output \",output.shape)\n",
    "       # test_loss = criterion(test_output, test_img) + criterion(z[:,:7], label) /(1e)  #  + 1e-5*  criterion(test_z[:,:7], test_label) \n",
    "        test_loss= (( criterion_none(test_output, test_img)/(test_img.sum(dim=3).sum(dim=2).sum(dim=1))).mean())  + (criterion_none(test_z[:,:7], test_label) /(1e10)).mean() \n",
    "        \n",
    "        test_loss_recon= (( criterion_none(test_output, test_img)/(test_img.sum(dim=3).sum(dim=2).sum(dim=1))).mean()) \n",
    "        test_loss_latent= (criterion_none(test_z[:,:7], test_label) /(1e10)).mean() \n",
    "        \n",
    "        test_MSE_loss = nn.MSELoss()(test_output, test_img)\n",
    "        batch_size = test_img.size(0)\n",
    "        test_total_loss += test_loss.item() * batch_size\n",
    "        test_total_mse += test_MSE_loss.item() * batch_size\n",
    "        test_total_recon+= test_loss_recon.item() * batch_size\n",
    "        test_total_latent+= test_loss_latent.item() * batch_size\n",
    "\n",
    "\n",
    "        test_num_examples += batch_size\n",
    "\n",
    "    writer.add_scalar('Loss/train',total_loss / num_examples,epoch)\n",
    "    writer.add_scalar('Mse/train', total_mse / num_examples,epoch)   \n",
    "    writer.add_scalar('Recon/train', total_recon / num_examples,epoch)        \n",
    "    writer.add_scalar('Latent/train', total_latent / num_examples,epoch)        \n",
    "    writer.add_scalar('Loss/test',test_total_loss / test_num_examples,epoch)\n",
    "    writer.add_scalar('Mse/test', test_total_mse / test_num_examples,epoch)\n",
    "    writer.add_scalar('Recon/test', test_total_recon / test_num_examples,epoch)        \n",
    "    writer.add_scalar('Latent/test', test_total_latent / test_num_examples,epoch)   \n",
    "    \n",
    "    \n",
    "    print('epoch [{}/{}], loss:{:.6f}, MSE_loss:{:.6f}, recon_loss:{:.6f}, latent_loss:{:.6f}'\n",
    "          .format(epoch + 1, num_epochs, total_loss / num_examples, total_mse/ num_examples, total_recon / num_examples, total_latent/ num_examples))     \n",
    "    \n",
    "    print('epoch [{}/{}], test_loss:{:.6f}, test_MSE_loss:{:.6f}, test_recon_loss:{:.6f}, test_latent_loss:{:.6f}'\n",
    "          .format(epoch + 1, num_epochs, test_total_loss / num_examples, test_total_mse/ num_examples, test_total_recon / num_examples, test_total_latent/ num_examples))   \n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        x = to_img(img.cpu().data)\n",
    "        x_hat = to_img(output.cpu().data)\n",
    "        test_x = to_img(test_img.cpu().data)    ########## change name \n",
    "        test_x_hat = to_img(test_output.cpu().data)\n",
    "        torch.save(x, './gal_img1001/exp411_x_{}.pt'.format(epoch))\n",
    "        torch.save(x_hat, './gal_img1001/exp411_x_hat_{}.pt'.format(epoch))\n",
    "        torch.save(test_x, './gal_img1001/exp411_test_x_{}.pt'.format(epoch))\n",
    "        torch.save(test_x_hat, './gal_img1001/exp411_test_x_hat_{}.pt'.format(epoch))\n",
    "        torch.save(model.state_dict(), './gal_img1001/exp411_{}.pth'.format(epoch))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6114, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss= (( criterion_none(output, img)/(img.sum(dim=3).sum(dim=2).sum(dim=1))).mean())* batch_size  + criterion_mean(z[:,:7], label) /(1e10) \n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0095, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(( criterion_none(output, img)/(img.sum(dim=3).sum(dim=2).sum(dim=1))).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " criterion_mean(z[:,:7], label) /(1e10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0019, device='cuda:0', grad_fn=<L1LossBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_mean(output, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(( criterion_mean(output, img)/(img.sum(dim=3).sum(dim=2).sum(dim=1)))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(z[:,:7], label)/1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(output, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4.7/1878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "a=criterion(output, img); \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=output.padding(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss(reduction='none')\n",
    "a=criterion(output, img)/(img.sum(dim=3).sum(dim=2).sum(dim=1)); \n",
    "a.shape\n",
    "a.mean()   # should i use a.mean * batch size as loss here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=criterion(output, img);\n",
    "o.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=(img.sum(dim=3).sum(dim=2).sum(dim=1));\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(o/s).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(o/s)[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(o[0]/s[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(o.view(64,64*64)).sum(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(o[0]/s[0]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(o[0]/s[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss(reduction='none')\n",
    "a=criterion(output, img)/(img.sum(dim=3).sum(dim=2).sum(dim=1)); \n",
    "a[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum(dim=3).sum(dim=2).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss(reduction='mean')\n",
    "\n",
    "b=torch.zeros(1)\n",
    "for i in range(64): \n",
    "    a=criterion(output[i]/img[i].sum(), img[i]/img[i].sum())\n",
    "    b=b+a \n",
    "    \n",
    "b    # b is not equal to a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss(reduction='mean')\n",
    "criterion(output, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b/64   # b/64 =a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(output[0]/img[0].sum(), img[0]/img[0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ=(img.sum(dim=3).sum(dim=2).sum(dim=1));\n",
    "summ.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.sum().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.sum(dim=3).sum(dim=2).sum(dim=1)  # img 64*1*64*64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "criterion(output, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " criterion(output, img)/2064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b/64 * 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=torch.zeros(1)\n",
    "for i in range(64): \n",
    "    a=criterion(output[i], img[i])\n",
    "    b=b+a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b/img.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(output/img.sum(), img/img.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(z[:,:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " criterion(output, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('epoch [{}/{}], loss:{:.6f}, MSE_loss:{:.6f}, recon_loss:{:.6f}, latent_loss:{:.6f}'\n",
    "          .format(epoch + 1, num_epochs, total_loss / num_examples, total_mse/ num_examples, total_recon / num_examples, total_latent/ num_examples))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        loss= ( criterion_none(output, img)/(img.sum(dim=3).sum(dim=2).sum(dim=1))) #  .mean())  #* batch_size # + criterion_mean(z[:,:7], label) /(1e9) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_none(output, img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
